{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDSA - Climate Change Belief Analysis 2021\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "-----------------\n",
    "With climate change considered a problem throughout the world many companies have taken the initiative to develope enviromentallyy friendly products and services to aim in lessening their carbon footprint. These compannies, however, often find it difficult to guage how their products and services may be percieved and therefore require a means of determining people's views on climate change. By analysing tweets about climate change the sentiment/opinion of the person writing that tweet can be captured and used to provide insight into who is anti or pro climate change and thus guide companies of who to target their products/services to. In this classification problem the aim was to accurately classify sentiments for a collection of tweets about climate change. To do this five, namely LinearSVC, Naive Bayes Multinomial, Random Forest, K-Nearest Neighbors and Logistic Regression classifier algorithms were used to build models to classify/predict tweet sentiments. Each of the models were assessed using several classification metrics, with the LinearSVC classifier displaying the best scores for the data at hand. We subsequently used a Grid Search to improve on the hyperparameters of LinearSVC in an attempt to improve its classifying ability. \n",
    "\n",
    "\n",
    "<img src = 'https://media3.giphy.com/media/k4ZItrTKDPnSU/200.gif'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "---------------\n",
    "1. [Introduction](#introduction)\n",
    "2. [Import Packages](#import)\n",
    "3. [Loading Data and Exploratory Data Analysis (EDA)](#load-data)\n",
    "4. [Pre-Processing and further EDA](#preprocess)\n",
    "5. [Model Building](#model-building)\n",
    "    * [LinearSVC](#linearsvc)\n",
    "    * [Naive Bayes](#naive-bayes)\n",
    "    * [Random Forest](#random-forest)\n",
    "    * [KNeighbors](#kneighbors)\n",
    "    * [Logistic Regression](#logistic-regression)\n",
    "6. [Model Assessment](#model-assess)\n",
    "7. [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## 1. Introduction\n",
    "---------------\n",
    "Climate change is the phenomenon of an increasing number of greenhouse gases within the earth's atmosphere that is accompanied by major shifts in weather patterns. This is largely human-induced and is as a result of increased levels of atmospheric carbon dioxide produced by the use of fossil fuels for basic living neccesities as well as large industrial processes. The effects of climate change affect the livelihoods of both people and animals and is experienced via intense drought, storms, heat waves, rising sea levels, melting glaciers and warming oceans, Furthermore, as climate change worsens, dangerous weather events are becoming more frequent or severe.\n",
    "\n",
    "<img src = 'https://media.giphy.com/media/hPovBcQ3c1g9W/giphy.gif'></img>\n",
    "\n",
    "Over several years, many companies have attempted to implemt startegies around lessening their environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. However, problems they experience include guaging how their products may be recieved based on people's views and opinions of climate change. By determining how people perceive climate change and whether or not they believe it is a real threat, these companies can improve on their market research efforts. Additionally, access to a large collection of consumer sentiments that also spans multiple demographic and geographic categories will influence company insights and their future marketing strategies allowing them to find the right target market to direct their products and efforts toward.\n",
    "\n",
    "In the context of climate change and sustainable companies, Team_TS1 aim to provide a means for such companies to determine the views or sentiments of people towards climate change. To do this, tweets pertaining to climate change will be looked at and used to train a classification model in order to accurately classify the opinions behind those tweets, into those who believe in climate change and those who do not. This notebook details the work flow of Team_TS1 in building, training and assessing different classifier models to provide a suitable solution that can be implemented in future marketing strategies of climate concious companies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "## 2. Import Packages\n",
    "--------------------\n",
    "To carry out EDA, model building and assessment of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:06.21794Z",
     "iopub.status.busy": "2021-06-22T09:42:06.217609Z",
     "iopub.status.idle": "2021-06-22T09:42:06.583334Z",
     "shell.execute_reply": "2021-06-22T09:42:06.582211Z",
     "shell.execute_reply.started": "2021-06-22T09:42:06.21791Z"
    }
   },
   "outputs": [],
   "source": [
    "# import comet_ml\n",
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:10.92438Z",
     "iopub.status.busy": "2021-06-22T09:42:10.924107Z",
     "iopub.status.idle": "2021-06-22T09:42:13.148787Z",
     "shell.execute_reply": "2021-06-22T09:42:13.147572Z",
     "shell.execute_reply.started": "2021-06-22T09:42:10.924357Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy and Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualisations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit Learn \n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#Extra\n",
    "from wordcloud import WordCloud\n",
    "import pickle\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load-data\"></a>\n",
    "## 3. Loading Data and Exploratory Data Analysis (EDA)\n",
    "-------------------\n",
    "The data is provided in two files: train.csv and test_with_no_labels.csv and pertains to climate change tweets collected between Apr 27, 2015 and Feb 21, 2018. The train.csv will be used to train the classifier model and the test_no_labels.csv will be used to test the model's classifying accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Training Dataset\n",
    "-----------\n",
    "The training set has 15819 rows and 3 columns, sentiment, made up of integer type data, message, made up of object type data and tweetid, made up of integer type data. Each row represents one observation and each column, a feature. \n",
    "\n",
    "**Columns:**\n",
    "* **message** : the written tweet, on climate change.\n",
    "* **tweetid** : identifier of a status/message on twitter\n",
    "* **sentiment** : expresses the view/opinion of climate change (Belief or Disbelief in  climate change, ranges from -1 to 2)\n",
    "        - -1. Anti - Climate Change: the tweet does not believe in man-made climate change\n",
    "        -  0. Neutral: the tweet neither supports nor refutes the belief of man-made climate change \n",
    "        -  1. Pro - Climate Change: the tweet supports the belief of man-made climate change\n",
    "        -  2. News: the tweet links to factual news about climate change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:35.212671Z",
     "iopub.status.busy": "2021-06-22T09:42:35.21239Z",
     "iopub.status.idle": "2021-06-22T09:42:35.296402Z",
     "shell.execute_reply": "2021-06-22T09:42:35.295514Z",
     "shell.execute_reply.started": "2021-06-22T09:42:35.212646Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading and reading train.csv to a Dataframe\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:37.607117Z",
     "iopub.status.busy": "2021-06-22T09:42:37.606808Z",
     "iopub.status.idle": "2021-06-22T09:42:37.638045Z",
     "shell.execute_reply": "2021-06-22T09:42:37.636607Z",
     "shell.execute_reply.started": "2021-06-22T09:42:37.607093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Overview of the train_df dataset\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:39.355213Z",
     "iopub.status.busy": "2021-06-22T09:42:39.354922Z",
     "iopub.status.idle": "2021-06-22T09:42:39.372729Z",
     "shell.execute_reply": "2021-06-22T09:42:39.372223Z",
     "shell.execute_reply.started": "2021-06-22T09:42:39.35519Z"
    }
   },
   "outputs": [],
   "source": [
    "# View first five rows of train_df\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Testing Dataset\n",
    "------------\n",
    "The testing set has 10546 rows and 2 columns; message and tweetid. The sentiment is to be predicted by classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:43.324075Z",
     "iopub.status.busy": "2021-06-22T09:42:43.323776Z",
     "iopub.status.idle": "2021-06-22T09:42:43.38284Z",
     "shell.execute_reply": "2021-06-22T09:42:43.38229Z",
     "shell.execute_reply.started": "2021-06-22T09:42:43.324052Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading and reading test_with_no_labels.csv to a Dataframe\n",
    "test = pd.read_csv('test_with_no_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:44.46819Z",
     "iopub.status.busy": "2021-06-22T09:42:44.467851Z",
     "iopub.status.idle": "2021-06-22T09:42:44.478111Z",
     "shell.execute_reply": "2021-06-22T09:42:44.476877Z",
     "shell.execute_reply.started": "2021-06-22T09:42:44.468165Z"
    }
   },
   "outputs": [],
   "source": [
    "# View first five rows of test_df\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:45.943603Z",
     "iopub.status.busy": "2021-06-22T09:42:45.943315Z",
     "iopub.status.idle": "2021-06-22T09:42:45.956202Z",
     "shell.execute_reply": "2021-06-22T09:42:45.955659Z",
     "shell.execute_reply.started": "2021-06-22T09:42:45.943574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Overview of the test_df dataset\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. EDA of Training Data\n",
    "-----------\n",
    "**Distribution of the Response**\n",
    "\n",
    "The distribution of the label variable (sentiment) provides insight into the frequencies per category of the sentiment (-1 to 2) expressed by each tweet. This gives an indication of the more popular vs unpopular opinions on climate change. Given the categorical nature of this variable a countplot provides the best insight into the frequencies for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:50.200238Z",
     "iopub.status.busy": "2021-06-22T09:42:50.199858Z",
     "iopub.status.idle": "2021-06-22T09:42:50.203931Z",
     "shell.execute_reply": "2021-06-22T09:42:50.203421Z",
     "shell.execute_reply.started": "2021-06-22T09:42:50.200215Z"
    }
   },
   "outputs": [],
   "source": [
    "def change_to_words(sentiment):\n",
    "    if sentiment == -1:\n",
    "        return 'Anti'\n",
    "    elif sentiment == 0:\n",
    "        return 'Neutral'\n",
    "    elif sentiment == 1:\n",
    "        return 'Pro'\n",
    "    else:\n",
    "        return 'News'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:51.429875Z",
     "iopub.status.busy": "2021-06-22T09:42:51.429487Z",
     "iopub.status.idle": "2021-06-22T09:42:51.43686Z",
     "shell.execute_reply": "2021-06-22T09:42:51.43616Z",
     "shell.execute_reply.started": "2021-06-22T09:42:51.42985Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiments = train['sentiment'].apply(change_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:42:52.626126Z",
     "iopub.status.busy": "2021-06-22T09:42:52.625731Z",
     "iopub.status.idle": "2021-06-22T09:42:53.134218Z",
     "shell.execute_reply": "2021-06-22T09:42:53.133131Z",
     "shell.execute_reply.started": "2021-06-22T09:42:52.626102Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')\n",
    "fig, ax = plt.subplots(ncols=2, \n",
    "                         nrows=1, \n",
    "                         figsize=(20, 10), \n",
    "                         dpi=100)\n",
    "\n",
    "sns.countplot(sentiments, ax=ax[0], palette = ['green', 'royalblue', 'orange', 'red'])\n",
    "\n",
    "labels = ['Pro', 'News', 'Neutral', 'Anti'] \n",
    "\n",
    "ax[1].pie(sentiments.value_counts(),\n",
    "            labels =labels,\n",
    "            autopct = '%1.0f%%',\n",
    "            startangle = 90,\n",
    "            shadow = True,\n",
    "            explode = (0.0, 0.1, 0.0, 0.0), \n",
    "            colors = ['green', 'royalblue', 'orange', 'red'], \n",
    "            textprops = {'fontsize': 15})\n",
    "\n",
    "fig.suptitle('Sentiment Distribution', fontsize = 30)\n",
    "plt.legend(title = 'Sentiments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of sentiments shows a clear difference in the frequencies observed for each sentiment, with the 'Pro' climate change tweets making up majority of the opinions expressed within this data set at over 8000 counts. 'Anti' climate changes tweets make up the lowest number of opinons with just over 1000 counts and with more people having a neutral response towards climate change than dibelieving in it. The number of News/factual tweets is higher than both that of 'Anti' and 'Neutral' views over 3000 views. \n",
    "\n",
    "The following table of value counts further describes the difference in frequency between each sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:43:00.985708Z",
     "iopub.status.busy": "2021-06-22T09:43:00.985439Z",
     "iopub.status.idle": "2021-06-22T09:43:01.002677Z",
     "shell.execute_reply": "2021-06-22T09:43:01.000782Z",
     "shell.execute_reply.started": "2021-06-22T09:43:00.985685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Total number of observations for each sentiment\n",
    "sentiment_counts = pd.DataFrame(train['sentiment'].value_counts())\n",
    "sentiment_counts['View'] = ['Pro', 'News/Factual', 'Neutral', 'Anti']\n",
    "sentiment_counts.sort_index(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocess\"></a>\n",
    "## 4. Pre-Processing and further EDA\n",
    "--------------\n",
    "#### <u>Prodecure for Pre-Processing</u>\n",
    "* Hashtag Extraction\n",
    "* Data Cleaning\n",
    "* Tokenisation\n",
    "* Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:29.438641Z",
     "iopub.status.busy": "2021-06-22T09:44:29.438309Z",
     "iopub.status.idle": "2021-06-22T09:44:29.443677Z",
     "shell.execute_reply": "2021-06-22T09:44:29.442712Z",
     "shell.execute_reply.started": "2021-06-22T09:44:29.438611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy of the train dataset to analyse\n",
    "df_train = train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Hashtag Extraction (#)\n",
    "--------------\n",
    "Hashtags are used to categorize tweets, so we will be extracting words starting with a `#` to see how many times they occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:33.440463Z",
     "iopub.status.busy": "2021-06-22T09:44:33.439936Z",
     "iopub.status.idle": "2021-06-22T09:44:33.44374Z",
     "shell.execute_reply": "2021-06-22T09:44:33.443223Z",
     "shell.execute_reply.started": "2021-06-22T09:44:33.440438Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_hashtags(post):\n",
    "    post_ = [word.replace('#', '') for word in post.split() if word.startswith('#')]\n",
    "    return post_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:34.329902Z",
     "iopub.status.busy": "2021-06-22T09:44:34.329515Z",
     "iopub.status.idle": "2021-06-22T09:44:34.630932Z",
     "shell.execute_reply": "2021-06-22T09:44:34.629916Z",
     "shell.execute_reply.started": "2021-06-22T09:44:34.329877Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['hashtags'] = df_train['message'].apply(extract_hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:35.938685Z",
     "iopub.status.busy": "2021-06-22T09:44:35.938088Z",
     "iopub.status.idle": "2021-06-22T09:44:35.953833Z",
     "shell.execute_reply": "2021-06-22T09:44:35.952141Z",
     "shell.execute_reply.started": "2021-06-22T09:44:35.938645Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all hashtags has been extracted, we can go ahead and clean the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Cleaning\n",
    "------------\n",
    "\n",
    "**Noisy information to remove:**\n",
    "* URL's\n",
    "* mentions\n",
    "* stopwords\n",
    "* punctuations\n",
    "* numbers and alphanumeric words\n",
    "* extra whitespaces\n",
    "\n",
    "Making everything lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:50.433088Z",
     "iopub.status.busy": "2021-06-22T09:44:50.432731Z",
     "iopub.status.idle": "2021-06-22T09:44:50.465166Z",
     "shell.execute_reply": "2021-06-22T09:44:50.464071Z",
     "shell.execute_reply.started": "2021-06-22T09:44:50.433059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Remove URL's\n",
    "def remove_links(df, column):\n",
    "    regex_pattern = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    df[column] = df[column].replace(to_replace = regex_pattern, \n",
    "                                    value = '', \n",
    "                                    regex = True)\n",
    "    \n",
    "# Remove mentions\n",
    "def remove_mentions(post):\n",
    "    post_ = ' '.join([word for word in post.split() if not word.startswith('@')])\n",
    "    return post_\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "def remove_stopwords(post):\n",
    "    post = ' '.join([word for word in post.split() if word not in stop_words])\n",
    "    return post\n",
    "\n",
    "# Remove punctuations\n",
    "def remove_punctuation(post):\n",
    "    post = ''.join([x for x in post if x not in string.punctuation])\n",
    "    return post\n",
    "\n",
    "# Remove numbers and alphanumeric words\n",
    "def return_alpha(post):\n",
    "    post_ = ' '.join([word for word in post.split() if word.isalpha()])\n",
    "    return post_\n",
    "\n",
    "# Remove extra spaces\n",
    "def remove_spaces(df, column):\n",
    "    regex_p = r'\\s\\s+'\n",
    "    df[column] = df[column].replace(to_replace = regex_p, \n",
    "                                    value = '', \n",
    "                                    regex = True)\n",
    "# Making everything lowercase\n",
    "df_train['message'] = df_train['message'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:51.423595Z",
     "iopub.status.busy": "2021-06-22T09:44:51.423266Z",
     "iopub.status.idle": "2021-06-22T09:44:52.291682Z",
     "shell.execute_reply": "2021-06-22T09:44:52.290261Z",
     "shell.execute_reply.started": "2021-06-22T09:44:51.423567Z"
    }
   },
   "outputs": [],
   "source": [
    "remove_links(df_train, 'message')\n",
    "df_train['message'] = df_train['message'].apply(remove_mentions)\n",
    "df_train['message'] = df_train['message'].apply(remove_stopwords)\n",
    "df_train['message'] = df_train['message'].apply(remove_punctuation)\n",
    "df_train['message'] = df_train['message'].apply(return_alpha)\n",
    "remove_spaces(df_train, 'message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:44:54.999826Z",
     "iopub.status.busy": "2021-06-22T09:44:54.999528Z",
     "iopub.status.idle": "2021-06-22T09:44:55.011772Z",
     "shell.execute_reply": "2021-06-22T09:44:55.010454Z",
     "shell.execute_reply.started": "2021-06-22T09:44:54.999801Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets needs to be tokenised to help get a better understanding of the context. Let's go ahead and tokenise of tweets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Tokenisation\n",
    "------------\n",
    "Tokenization is a way of separating a piece of text into smaller units. Tokens can be either words, characters or subwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:00.696772Z",
     "iopub.status.busy": "2021-06-22T09:45:00.696428Z",
     "iopub.status.idle": "2021-06-22T09:45:00.700501Z",
     "shell.execute_reply": "2021-06-22T09:45:00.699611Z",
     "shell.execute_reply.started": "2021-06-22T09:45:00.696743Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(post):\n",
    "    post_ = word_tokenize(post)\n",
    "    return post_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:01.603521Z",
     "iopub.status.busy": "2021-06-22T09:45:01.603109Z",
     "iopub.status.idle": "2021-06-22T09:45:03.216141Z",
     "shell.execute_reply": "2021-06-22T09:45:03.214896Z",
     "shell.execute_reply.started": "2021-06-22T09:45:01.603496Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['tokens'] = df_train['message'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:05.152738Z",
     "iopub.status.busy": "2021-06-22T09:45:05.152429Z",
     "iopub.status.idle": "2021-06-22T09:45:05.167229Z",
     "shell.execute_reply": "2021-06-22T09:45:05.166114Z",
     "shell.execute_reply.started": "2021-06-22T09:45:05.152712Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will be lemmatizing all the words to their base form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Lemmatization\n",
    "------\n",
    "Lemmatizing words to their base form will ensure that words with similar meaning be represented in the same way. \n",
    "\n",
    "Stemming is not an option because it looks for similarity in words and often returns words that have no meaning/value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:12.865958Z",
     "iopub.status.busy": "2021-06-22T09:45:12.865553Z",
     "iopub.status.idle": "2021-06-22T09:45:12.870105Z",
     "shell.execute_reply": "2021-06-22T09:45:12.869076Z",
     "shell.execute_reply.started": "2021-06-22T09:45:12.865933Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:14.186272Z",
     "iopub.status.busy": "2021-06-22T09:45:14.185628Z",
     "iopub.status.idle": "2021-06-22T09:45:14.192392Z",
     "shell.execute_reply": "2021-06-22T09:45:14.191116Z",
     "shell.execute_reply.started": "2021-06-22T09:45:14.186233Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatize_(post):\n",
    "    row = []\n",
    "    for word in post:\n",
    "        lem = lemmatizer.lemmatize(word)\n",
    "        row.append(lem)\n",
    "    post_ = ' '.join(row)\n",
    "    return post_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:15.990483Z",
     "iopub.status.busy": "2021-06-22T09:45:15.989835Z",
     "iopub.status.idle": "2021-06-22T09:45:18.269749Z",
     "shell.execute_reply": "2021-06-22T09:45:18.268673Z",
     "shell.execute_reply.started": "2021-06-22T09:45:15.990458Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['lemmatized'] = df_train['tokens'].apply(lemmatize_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:20.358549Z",
     "iopub.status.busy": "2021-06-22T09:45:20.358272Z",
     "iopub.status.idle": "2021-06-22T09:45:20.372039Z",
     "shell.execute_reply": "2021-06-22T09:45:20.371473Z",
     "shell.execute_reply.started": "2021-06-22T09:45:20.358526Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the pre-processing is done, we can visual and find trends in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Further EDA\n",
    "------\n",
    "We will be looking at:\n",
    "* Most frequently used words\n",
    "* Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most Frequently used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:24.92409Z",
     "iopub.status.busy": "2021-06-22T09:45:24.92381Z",
     "iopub.status.idle": "2021-06-22T09:45:24.928735Z",
     "shell.execute_reply": "2021-06-22T09:45:24.927296Z",
     "shell.execute_reply.started": "2021-06-22T09:45:24.924067Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:25.834116Z",
     "iopub.status.busy": "2021-06-22T09:45:25.833723Z",
     "iopub.status.idle": "2021-06-22T09:45:25.839497Z",
     "shell.execute_reply": "2021-06-22T09:45:25.837959Z",
     "shell.execute_reply.started": "2021-06-22T09:45:25.834093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Put all words in a single string so it can be processed by the wordcloud\n",
    "def change_to_string(sentiment):\n",
    "    words = []\n",
    "    for post in df_train[df_train['sentiment'] == sentiment]['lemmatized']:\n",
    "        for word in post.split():\n",
    "            words.append(word)\n",
    "    text = ' '.join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:26.91025Z",
     "iopub.status.busy": "2021-06-22T09:45:26.909864Z",
     "iopub.status.idle": "2021-06-22T09:45:26.972861Z",
     "shell.execute_reply": "2021-06-22T09:45:26.971952Z",
     "shell.execute_reply.started": "2021-06-22T09:45:26.910227Z"
    }
   },
   "outputs": [],
   "source": [
    "anti_climate = change_to_string(-1)\n",
    "pro_climate = change_to_string(1)\n",
    "neutral_climate = change_to_string(0)\n",
    "news_climate = change_to_string(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:27.844984Z",
     "iopub.status.busy": "2021-06-22T09:45:27.844596Z",
     "iopub.status.idle": "2021-06-22T09:45:29.00099Z",
     "shell.execute_reply": "2021-06-22T09:45:28.99987Z",
     "shell.execute_reply.started": "2021-06-22T09:45:27.844954Z"
    }
   },
   "outputs": [],
   "source": [
    "anti_cloud = WordCloud(\n",
    "    background_color ='white', \n",
    "    max_font_size = 130, \n",
    "    max_words = 20, \n",
    "    colormap = \"Reds\").generate(anti_climate)\n",
    "\n",
    "pro_cloud = WordCloud(\n",
    "    background_color ='white', \n",
    "    max_font_size = 130, \n",
    "    max_words = 20, \n",
    "    colormap = \"Greens\").generate(pro_climate)\n",
    "\n",
    "neutral_cloud = WordCloud( \n",
    "    background_color ='white', \n",
    "    max_font_size = 130, \n",
    "    max_words = 20, \n",
    "    colormap = \"Oranges\").generate(neutral_climate)\n",
    "\n",
    "news_cloud = WordCloud(\n",
    "    background_color ='white', \n",
    "    max_font_size = 130, \n",
    "    max_words = 20, \n",
    "    colormap = \"Blues\").generate(news_climate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:45:51.902188Z",
     "iopub.status.busy": "2021-06-22T09:45:51.901819Z",
     "iopub.status.idle": "2021-06-22T09:45:52.986339Z",
     "shell.execute_reply": "2021-06-22T09:45:52.985132Z",
     "shell.execute_reply.started": "2021-06-22T09:45:51.902157Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(35, 25))\n",
    "ax[0, 0].imshow(pro_cloud, interpolation=\"bilinear\")\n",
    "ax[0, 1].imshow(anti_cloud, interpolation=\"bilinear\")\n",
    "ax[1, 0].imshow(neutral_cloud, interpolation=\"bilinear\")\n",
    "ax[1, 1].imshow(news_cloud, interpolation=\"bilinear\")\n",
    "\n",
    "ax[0, 0].set_title('\\nPro climate change\\n', fontsize = 40, fontweight = 'bold')\n",
    "ax[0, 1].set_title('\\nAnti climate change\\n', fontsize = 40, fontweight = 'bold')\n",
    "ax[1, 0].set_title('\\nNeutral\\n', fontsize = 40, fontweight = 'bold')\n",
    "ax[1, 1].set_title('\\nNews\\n', fontsize = 40, fontweight = 'bold')\n",
    "\n",
    "ax[0, 0].axis(\"off\")\n",
    "ax[0, 1].axis(\"off\")\n",
    "ax[1, 0].axis(\"off\")\n",
    "ax[1, 1].axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:14.903814Z",
     "iopub.status.busy": "2021-06-22T09:46:14.903486Z",
     "iopub.status.idle": "2021-06-22T09:46:14.909431Z",
     "shell.execute_reply": "2021-06-22T09:46:14.908542Z",
     "shell.execute_reply.started": "2021-06-22T09:46:14.903785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get hashtags for a specific sentiment\n",
    "def get_hashtags(sentiment):\n",
    "    hashtags = []\n",
    "\n",
    "    for hashtag in df_train[df_train['sentiment'] == sentiment]['hashtags']:\n",
    "        for word in hashtag:\n",
    "            hashtags.append(word.lower())\n",
    "            \n",
    "    return pd.Series(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:16.192132Z",
     "iopub.status.busy": "2021-06-22T09:46:16.191772Z",
     "iopub.status.idle": "2021-06-22T09:46:16.221841Z",
     "shell.execute_reply": "2021-06-22T09:46:16.220739Z",
     "shell.execute_reply.started": "2021-06-22T09:46:16.192102Z"
    }
   },
   "outputs": [],
   "source": [
    "anti = get_hashtags(-1).value_counts()\n",
    "neutral = get_hashtags(0).value_counts()\n",
    "pro = get_hashtags(1).value_counts()\n",
    "news = get_hashtags(2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:18.012292Z",
     "iopub.status.busy": "2021-06-22T09:46:18.01191Z",
     "iopub.status.idle": "2021-06-22T09:46:18.247902Z",
     "shell.execute_reply": "2021-06-22T09:46:18.246613Z",
     "shell.execute_reply.started": "2021-06-22T09:46:18.012263Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = anti[:15],\n",
    "    y = list(anti.index)[:15],\n",
    "    palette = 'Reds_d'\n",
    ")\n",
    "\n",
    "plt.title('Anti Climate Change Hashtags', fontsize = 15, fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:20.965688Z",
     "iopub.status.busy": "2021-06-22T09:46:20.965394Z",
     "iopub.status.idle": "2021-06-22T09:46:21.200225Z",
     "shell.execute_reply": "2021-06-22T09:46:21.199205Z",
     "shell.execute_reply.started": "2021-06-22T09:46:20.965659Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = neutral[:15],\n",
    "    y = list(neutral.index)[:15], \n",
    "    palette = 'Oranges_d'\n",
    ")\n",
    "plt.title('Neutral Hashtags', fontsize = 15, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:23.769253Z",
     "iopub.status.busy": "2021-06-22T09:46:23.768928Z",
     "iopub.status.idle": "2021-06-22T09:46:24.034177Z",
     "shell.execute_reply": "2021-06-22T09:46:24.033318Z",
     "shell.execute_reply.started": "2021-06-22T09:46:23.769225Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = pro[:15],\n",
    "    y = list(pro.index)[:15], \n",
    "    palette = 'Greens_d'\n",
    ")\n",
    "plt.title('Pro Climate Change Hashtags', fontsize = 15, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:27.562288Z",
     "iopub.status.busy": "2021-06-22T09:46:27.561913Z",
     "iopub.status.idle": "2021-06-22T09:46:27.781796Z",
     "shell.execute_reply": "2021-06-22T09:46:27.781223Z",
     "shell.execute_reply.started": "2021-06-22T09:46:27.562264Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "    x = news[:15],\n",
    "    y = list(news.index)[:15], \n",
    "    palette = 'Blues_d'\n",
    ")\n",
    "plt.title('News Hashtags', fontsize = 15, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-building\"></a>\n",
    "## 5. Model Building \n",
    "---\n",
    "The model building section is only for model building not for comparison between each models results, that will be covered in the next section.\n",
    "<br></br>\n",
    "#### <b><u>Models being used:</u></b>\n",
    "<ul>\n",
    "    <li>LInearSVC</li>\n",
    "    <li>Naive Bayes</li>\n",
    "    <li>Random Forest</li>\n",
    "    <li>KNeighbors</li>\n",
    "    <li>Logistic Regression</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure for the model building section\n",
    "---\n",
    "<ol>\n",
    "    <li>Assign the independent variable and target variable to variables X and y, respectively</li>\n",
    "    <li>Split the data into a train and validation set</li>\n",
    "    <li>Create a pipeline to set workflow (contains vectorizer and model)</li>\n",
    "    <li>Fit the model with the train set</li>\n",
    "    \n",
    "</ol>\n",
    "<b><u>Note:</u></b> Step 3 to Step 4 will be repeated for all models. All models are run on their default hyperparameter setting to establish which model works best at predicting the data at hand.\n",
    "\n",
    "Each model was built through a Pipeline with a Tfidf-Vectorizer (Term Frequency Inverse Document Frequency). The algorithm for this vectorizer transforms text into a representation of numbers that reflect how significant a word is to a record in a collection or corpus. \n",
    "\n",
    "The output of the vectorizer can be controlled via several hyperparameters. Here the min_df, max_df and ngram_range hyperparameters were adjusted for each classifier to increase prediction capabilities of each model. Min_df and max_df stands for the frequency threshold of the words to be ignored from the vectorizer output if they appear less than or more than the values set for each respective hyperparameter. The ngram_range creates a sequence of N-words in a sentence for each word in a record, where N is an integer that stands for the number of words in the sequence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:49.368413Z",
     "iopub.status.busy": "2021-06-22T09:46:49.368116Z",
     "iopub.status.idle": "2021-06-22T09:46:49.372586Z",
     "shell.execute_reply": "2021-06-22T09:46:49.371951Z",
     "shell.execute_reply.started": "2021-06-22T09:46:49.368385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declaring the X and y variables\n",
    "X = train['message']\n",
    "y = train['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into 75% train and 25% test with a `random_state` of 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:46:52.930784Z",
     "iopub.status.busy": "2021-06-22T09:46:52.930503Z",
     "iopub.status.idle": "2021-06-22T09:46:52.939249Z",
     "shell.execute_reply": "2021-06-22T09:46:52.938439Z",
     "shell.execute_reply.started": "2021-06-22T09:46:52.93076Z"
    }
   },
   "outputs": [],
   "source": [
    "# splitting training dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting our data, we can begin to use it to train our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up of Tfidf vectorizer to run with each model in a Pipeline\n",
    "tfidf_v = TfidfVectorizer(ngram_range = (1, 2), min_df = 2, max_df = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linearsvc\"></a>\n",
    "### 5.1 LinearSVC\n",
    "----------\n",
    "\n",
    "Support Vector Machine (SVM) models are most commonly associated with classification tasks and are found to be among the more accurately classifying algorithms. The SVM algorithm plots each data point in an N-dimensional space, with N being the number of features present within the dataset. There are a number of hyperplanes that exist within the dimensional space with each hyperplane separating each class of data points to a certain extent. The algorithm will subsequently look for the ‘best’ hyperplane which would have the maximum distance between the classes of data points (maximum margin), distinctly separating each class/label.\n",
    "\n",
    "In this classification problem, a LinearSVC model was used to classify the tweet sentiments. The LinearSVC model uses a liblinear estimator which penalizes the intercept and minimizes the squared hinge loss function, compared to the liblinear estimators of a SVC() model that do not penalize the intercept. Liblinear estimators are optimized for a linear case and are able to converge quicker on larger amounts of data and is therefore quick in resolve=ing the problem. LinearSVC() uses a One-vs-All multiclass-reduction by splitting the multiclass dataset into multiple binary classification problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:47:18.593322Z",
     "iopub.status.busy": "2021-06-22T09:47:18.592877Z",
     "iopub.status.idle": "2021-06-22T09:47:18.596569Z",
     "shell.execute_reply": "2021-06-22T09:47:18.596098Z",
     "shell.execute_reply.started": "2021-06-22T09:47:18.593296Z"
    }
   },
   "outputs": [],
   "source": [
    "lsvc_ = Pipeline([\n",
    "    ('tfidf', tfidf_v),\n",
    "    ('lsvc', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:47:24.158208Z",
     "iopub.status.busy": "2021-06-22T09:47:24.157783Z",
     "iopub.status.idle": "2021-06-22T09:47:24.919938Z",
     "shell.execute_reply": "2021-06-22T09:47:24.918975Z",
     "shell.execute_reply.started": "2021-06-22T09:47:24.158184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2))),\n",
       "                ('lsvc', LinearSVC())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"naive-bayes\"></a>\n",
    "### 5.2 Naive Bayes\n",
    "-----------\n",
    "\n",
    "The Naive Bayes Classifier is among the faster computing classification algorithms, is mostly used in text classification/natural language processing problems and in cases where datasets have multiple classes. This algorithm uses Bayes theorem to predict the class of unknown data points using conditional probability, which is a measure of the probability of an event occurring given that another event has occurred. It assumes independence between the features of the data set and uses the Naive Bayesian equation to calculate the posterior probability for each class, with the highest posterior probability being the outcome of prediction. In the case of this classification problem the Multinomial variant of the Naive Bayes classifier built for sentiment prediction. This classifier assumes a feature vector where a given term is represented by the number/frequency of times it appears, the algorithm then determines the probability for each term and the predicted outcome is based on the highest probability. The main hyperparameter associated with the Multiomial Naive Bayes classifier is alpha (Laplace smoothing factor) that prevents the model from setting null probabilities when the frequency is zero while larger values of alpha assign higher probabilities to the missing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:47:50.001628Z",
     "iopub.status.busy": "2021-06-22T09:47:50.001233Z",
     "iopub.status.idle": "2021-06-22T09:47:50.005552Z",
     "shell.execute_reply": "2021-06-22T09:47:50.004516Z",
     "shell.execute_reply.started": "2021-06-22T09:47:50.001603Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_ = Pipeline([\n",
    "    ('tfidf', tfidf_v),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:47:57.626871Z",
     "iopub.status.busy": "2021-06-22T09:47:57.626563Z",
     "iopub.status.idle": "2021-06-22T09:47:58.229225Z",
     "shell.execute_reply": "2021-06-22T09:47:58.227626Z",
     "shell.execute_reply.started": "2021-06-22T09:47:57.626846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2))),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"random-forest\"></a>\n",
    "### 5.3 Random Forest\n",
    "------------\n",
    "\n",
    "Next, we built a model using the Random Forest classifier. This classifier creates a set of decision trees from randomly selected subsets of the training set. It then aggregates the votes from different decision trees to decide the final class of the test object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:48:17.911128Z",
     "iopub.status.busy": "2021-06-22T09:48:17.910768Z",
     "iopub.status.idle": "2021-06-22T09:48:17.915287Z",
     "shell.execute_reply": "2021-06-22T09:48:17.914461Z",
     "shell.execute_reply.started": "2021-06-22T09:48:17.911097Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_ = Pipeline([\n",
    "    ('tfidf', tfidf_v),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:48:25.990332Z",
     "iopub.status.busy": "2021-06-22T09:48:25.989954Z",
     "iopub.status.idle": "2021-06-22T09:48:50.416701Z",
     "shell.execute_reply": "2021-06-22T09:48:50.415989Z",
     "shell.execute_reply.started": "2021-06-22T09:48:25.990301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2))),\n",
       "                ('rf', RandomForestClassifier())])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"kneighbors\"></a>\n",
    "### 5.4 KNeighbors\n",
    "------------\n",
    "\n",
    "The KNeighborsClassifier uses the K Nearest Neighbors (KNN) algorithm to classify data. This algorithm is non-parametric and works by classifying the query point as the class of the majority of representatives among the nearest neighbors of the query/test data point (i.e if most of the query point’s neighbors are Class x, then the query point will be classified as Class x). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:48:59.313296Z",
     "iopub.status.busy": "2021-06-22T09:48:59.312795Z",
     "iopub.status.idle": "2021-06-22T09:48:59.31757Z",
     "shell.execute_reply": "2021-06-22T09:48:59.317087Z",
     "shell.execute_reply.started": "2021-06-22T09:48:59.313245Z"
    }
   },
   "outputs": [],
   "source": [
    "knn_ = Pipeline([\n",
    "    ('tfidf', tfidf_v),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:49:09.760873Z",
     "iopub.status.busy": "2021-06-22T09:49:09.760406Z",
     "iopub.status.idle": "2021-06-22T09:49:10.338089Z",
     "shell.execute_reply": "2021-06-22T09:49:10.336982Z",
     "shell.execute_reply.started": "2021-06-22T09:49:09.760846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2))),\n",
       "                ('knn', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"logistic-regression\"></a>\n",
    "### 5.5 Logistic Regression\n",
    "------------\n",
    "\n",
    "Logistic Regression is typically used for classification problems where there are two outcomes (binary). The model measures the relationship between the dependent variable (label) and one or more independent variables (our features), by estimating the probability of the first class (class 1). These probabilities are then transformed into binary values, by the logistic/sigmoid function, in order to actually make a prediction. This function is an S-shaped curve that takes any real-valued number and maps it into a value between the range of 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:49:24.302259Z",
     "iopub.status.busy": "2021-06-22T09:49:24.301932Z",
     "iopub.status.idle": "2021-06-22T09:49:24.306697Z",
     "shell.execute_reply": "2021-06-22T09:49:24.305534Z",
     "shell.execute_reply.started": "2021-06-22T09:49:24.302235Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_ = Pipeline([\n",
    "    ('tfidf', tfidf_v), \n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:49:31.888214Z",
     "iopub.status.busy": "2021-06-22T09:49:31.887889Z",
     "iopub.status.idle": "2021-06-22T09:49:36.789977Z",
     "shell.execute_reply": "2021-06-22T09:49:36.789096Z",
     "shell.execute_reply.started": "2021-06-22T09:49:31.888191Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henab\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf',\n",
       "                 TfidfVectorizer(max_df=0.8, min_df=2, ngram_range=(1, 2))),\n",
       "                ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models has been fitted, now we move to the Model Assessment section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-assess\"></a>\n",
    "## 6. Model Assessment \n",
    "--------------\n",
    "We will be comparing the performance of the models to see which one had a best performance.\n",
    "<br></br>\n",
    "- We will compare each model's `precision`, `recall` and `f1` scores to see which one performed the best\n",
    "\n",
    "The Precision score refers to the percentage of predictions that are correct (i.e out of all points classified as class one how many were correctly classified as class one). Recall scores reflect the fraction of each label that was correctly identified (i.e out of all true class ones how many were correctly predicted as class one). The f-1 score is a combination of both precision and recall, as a weighted harmonic mean and is useful for imbalanced classification. It falls between a range of 0 and 1.00, with a value of 1.00 indicating a model with perfect precision and recall and values close to zero suggesting a model with poor precision and recall. This score is also commonly used to compare classifier models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:50:24.049878Z",
     "iopub.status.busy": "2021-06-22T09:50:24.049609Z",
     "iopub.status.idle": "2021-06-22T09:50:27.555041Z",
     "shell.execute_reply": "2021-06-22T09:50:27.554475Z",
     "shell.execute_reply.started": "2021-06-22T09:50:24.049855Z"
    }
   },
   "outputs": [],
   "source": [
    "lsvc_y = lsvc_.predict(X_test)\n",
    "mnb_y = mnb_.predict(X_test)\n",
    "rf_y = rf_.predict(X_test)\n",
    "knn_y = knn_.predict(X_test)\n",
    "lr_y = lr_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:51:22.259065Z",
     "iopub.status.busy": "2021-06-22T09:51:22.258638Z",
     "iopub.status.idle": "2021-06-22T09:51:22.295931Z",
     "shell.execute_reply": "2021-06-22T09:51:22.294798Z",
     "shell.execute_reply.started": "2021-06-22T09:51:22.259028Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'precision': [\n",
    "        precision_score(y_test, lsvc_y, average = 'weighted'),\n",
    "        precision_score(y_test, mnb_y, average = 'weighted'),\n",
    "        precision_score(y_test, rf_y, average = 'weighted'),\n",
    "        precision_score(y_test, knn_y, average = 'weighted'),\n",
    "        precision_score(y_test, lr_y, average = 'weighted')\n",
    "    ],\n",
    "    'recall': [\n",
    "        recall_score(y_test, lsvc_y, average = 'weighted'),\n",
    "        recall_score(y_test, mnb_y, average = 'weighted'),\n",
    "        recall_score(y_test, rf_y, average = 'weighted'),\n",
    "        recall_score(y_test, knn_y, average = 'weighted'),\n",
    "        recall_score(y_test, lr_y, average = 'weighted')\n",
    "    ],\n",
    "    'f1': [\n",
    "        f1_score(y_test, lsvc_y, average = 'weighted'),\n",
    "        f1_score(y_test, mnb_y, average = 'weighted'),\n",
    "        f1_score(y_test, rf_y, average = 'weighted'),\n",
    "        f1_score(y_test, knn_y, average = 'weighted'),\n",
    "        f1_score(y_test, lr_y, average = 'weighted')\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:51:32.735843Z",
     "iopub.status.busy": "2021-06-22T09:51:32.735565Z",
     "iopub.status.idle": "2021-06-22T09:51:32.749489Z",
     "shell.execute_reply": "2021-06-22T09:51:32.748281Z",
     "shell.execute_reply.started": "2021-06-22T09:51:32.73582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.760004</td>\n",
       "      <td>0.765866</td>\n",
       "      <td>0.757522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.772611</td>\n",
       "      <td>0.680657</td>\n",
       "      <td>0.612546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.720970</td>\n",
       "      <td>0.712769</td>\n",
       "      <td>0.686340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighbors</th>\n",
       "      <td>0.656042</td>\n",
       "      <td>0.654614</td>\n",
       "      <td>0.653468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.748897</td>\n",
       "      <td>0.749178</td>\n",
       "      <td>0.728501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     precision    recall        f1\n",
       "LinearSVC             0.760004  0.765866  0.757522\n",
       "Naive Bayes           0.772611  0.680657  0.612546\n",
       "Random Forest         0.720970  0.712769  0.686340\n",
       "KNeighbors            0.656042  0.654614  0.653468\n",
       "Logistic Regression   0.748897  0.749178  0.728501"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics, index = [\n",
    "    'LinearSVC', \n",
    "    'Naive Bayes', \n",
    "    'Random Forest', \n",
    "    'KNeighbors', \n",
    "    'Logistic Regression'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairly high (> 0.5) precision, recall and f1 scores are displayed for all of the models tested in sentiment classification. Of these five, LinearSVC displays the best set of scores across all the metrics.**\n",
    "**In terms of f1 scores close second in terms of model performance is the Logistic Regression model,**\n",
    "\n",
    "UNFINISHED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe from above, `LinearSVC` performed the best when running the data on it's default hyperparameters. Therefore we will tune the LinearSVC model and see if it will perform better.\n",
    "\n",
    "<b>Procedure:</b>\n",
    "* Create a dictionary with hyperparameters to run a Grid Search\n",
    "* Pass the model and hyperparameters into a Cross Validation algorithm\n",
    "* Observe best parameters\n",
    "* Observe best score\n",
    "* Observe classification report and confusion matrix\n",
    "\n",
    "\n",
    "In an attempt to improve the prediction accuracy of the LinearSVC() classifier, the vectorizing, model building and model tuning was applied to each model using a Grid Search (GridSearchCV), in order to find the optimal hyperparameters that performs best with the input data for each classifier model. GridSearchCV tries all the combinations of the values passed in the dictionary and evaluates the model for each combination using the Cross-Validation method using a 'fit and score' method. K-folds of k = 5 are used for cross validation for each of the models. The data set is divided into k number of subsets/folds, the model is then trained on k-1 folds and the remaining fold is used to test the model's effectiveness. The model will iterate through each fold until all folds has served as a test set and the average k recorded accuracy (cross-validation accuracy) is used as the performance metric for the model.\n",
    "\n",
    "The LinearSVC() classifier consists of several tunable hyperparameters that can be used to improve on it’s classifying capabilities, here the hyperparameters C and class_weight were set during model building. The C hyperparameter controls the penalty strength, where small C values increase the regularization strength which creates simple models that under-fits the data and big C values lowers the regularization strength which increases the model’s complexity resulting in overfitting of the data. The class_weight hyperparameter handles a data imbalance, with ‘balanced’ meaning classes will be automatically weighted inversely proportional to how frequently they appear in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:52:32.630898Z",
     "iopub.status.busy": "2021-06-22T09:52:32.630622Z",
     "iopub.status.idle": "2021-06-22T09:52:32.63524Z",
     "shell.execute_reply": "2021-06-22T09:52:32.634559Z",
     "shell.execute_reply.started": "2021-06-22T09:52:32.630875Z"
    }
   },
   "outputs": [],
   "source": [
    "lsvc_params = {\n",
    "    'lsvc__C': [1, 0.5],\n",
    "    'lsvc__max_iter': [1000, 2000], \n",
    "    'lsvc__class_weight': ['balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:52:44.6536Z",
     "iopub.status.busy": "2021-06-22T09:52:44.653284Z",
     "iopub.status.idle": "2021-06-22T09:52:44.658405Z",
     "shell.execute_reply": "2021-06-22T09:52:44.657297Z",
     "shell.execute_reply.started": "2021-06-22T09:52:44.653576Z"
    }
   },
   "outputs": [],
   "source": [
    "lsvc_cv = GridSearchCV(\n",
    "    lsvc_,\n",
    "    param_grid = lsvc_params,\n",
    "    scoring = 'f1_weighted',\n",
    "    cv = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:52:56.492629Z",
     "iopub.status.busy": "2021-06-22T09:52:56.492371Z",
     "iopub.status.idle": "2021-06-22T09:54:30.210645Z",
     "shell.execute_reply": "2021-06-22T09:54:30.209107Z",
     "shell.execute_reply.started": "2021-06-22T09:52:56.492606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(max_df=0.8, min_df=2,\n",
       "                                                        ngram_range=(1, 2))),\n",
       "                                       ('lsvc', LinearSVC())]),\n",
       "             param_grid={'lsvc__C': [1, 0.5],\n",
       "                         'lsvc__class_weight': ['balanced'],\n",
       "                         'lsvc__max_iter': [1000, 2000]},\n",
       "             scoring='f1_weighted')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:42.514709Z",
     "iopub.status.busy": "2021-06-22T09:54:42.514429Z",
     "iopub.status.idle": "2021-06-22T09:54:42.520729Z",
     "shell.execute_reply": "2021-06-22T09:54:42.519437Z",
     "shell.execute_reply.started": "2021-06-22T09:54:42.514686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lsvc__C': 0.5, 'lsvc__class_weight': 'balanced', 'lsvc__max_iter': 1000}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:44.005627Z",
     "iopub.status.busy": "2021-06-22T09:54:44.005212Z",
     "iopub.status.idle": "2021-06-22T09:54:44.011243Z",
     "shell.execute_reply": "2021-06-22T09:54:44.01039Z",
     "shell.execute_reply.started": "2021-06-22T09:54:44.005594Z"
    }
   },
   "outputs": [],
   "source": [
    "lsvc_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:46.380553Z",
     "iopub.status.busy": "2021-06-22T09:54:46.379985Z",
     "iopub.status.idle": "2021-06-22T09:54:46.625856Z",
     "shell.execute_reply": "2021-06-22T09:54:46.624877Z",
     "shell.execute_reply.started": "2021-06-22T09:54:46.380517Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lsvc_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classification report displays several important classification metrics for each label being predicted by the model.  Precision, recall, f1, and support scores are all included in this report. The support score references the true number of instances of the class in the specified dataset. The classification report further includes the accuracy, macro and weighted average scores for each metric. The accuracy score relflects the overall performance of model as a ratio of correctly predicted observation to the total observations, however this metric gives the best insight into symmetric data One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets, therefore, other parameters need to be evaluated as well in order to determine the performance of your model.The macro average score refers to the unweighted mean of the metric for each label to being calculated independently to find the unweighted mean. Finally the weighted average score is the metric calculated for each label/class, and finds their average weighted support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:48.959823Z",
     "iopub.status.busy": "2021-06-22T09:54:48.959288Z",
     "iopub.status.idle": "2021-06-22T09:54:48.975557Z",
     "shell.execute_reply": "2021-06-22T09:54:48.974566Z",
     "shell.execute_reply.started": "2021-06-22T09:54:48.959793Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix simply depicts the number of correctly classified and incorrectly classified labels.  The diagonal elements of the matrix represent the number ofdata points for which the predicted label is equal to the true label, while off-diagonal elements are those that are mislabeled by the classifier. Higher diagonal values are indicative of many correctly predicted data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:54:54.978205Z",
     "iopub.status.busy": "2021-06-22T09:54:54.977878Z",
     "iopub.status.idle": "2021-06-22T09:54:55.171207Z",
     "shell.execute_reply": "2021-06-22T09:54:55.170692Z",
     "shell.execute_reply.started": "2021-06-22T09:54:54.978179Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    cmap = \"Blues_r\", \n",
    "    xticklabels = lsvc_cv.classes_, \n",
    "    yticklabels = lsvc_cv.classes_, \n",
    "    vmin = 0, \n",
    "    vmax = 3000, \n",
    "    annot = True, \n",
    "    fmt = 'g'\n",
    ")\n",
    "\n",
    "plt.ylabel('True values')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hyperparameter tuning, we can predict sentiments for the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Set\n",
    "No pre-processing is required for the test set as everythin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T10:00:42.870147Z",
     "iopub.status.busy": "2021-06-22T10:00:42.869738Z",
     "iopub.status.idle": "2021-06-22T10:00:43.252641Z",
     "shell.execute_reply": "2021-06-22T10:00:43.251408Z",
     "shell.execute_reply.started": "2021-06-22T10:00:42.870123Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_ = lsvc_cv.predict(test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T10:00:56.869971Z",
     "iopub.status.busy": "2021-06-22T10:00:56.869685Z",
     "iopub.status.idle": "2021-06-22T10:00:56.874355Z",
     "shell.execute_reply": "2021-06-22T10:00:56.873619Z",
     "shell.execute_reply.started": "2021-06-22T10:00:56.869946Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'tweetid': test['tweetid'], \n",
    "                           'sentiment': y_pred_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T10:01:41.211858Z",
     "iopub.status.busy": "2021-06-22T10:01:41.211564Z",
     "iopub.status.idle": "2021-06-22T10:01:41.220678Z",
     "shell.execute_reply": "2021-06-22T10:01:41.220162Z",
     "shell.execute_reply.started": "2021-06-22T10:01:41.211834Z"
    }
   },
   "outputs": [],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## 7. Conclusion\n",
    "--------\n",
    "Of the five models tested in sentiment analysis and classification of climate change tweets, the model with the best results (f1 score) was found to be the LinearSVC(). This is likely due to the LinearSVC() model looking at the interactions between the word frequencies of the vectorizer output, as well as being better suited to unstructured and semi-structured data like text. The best hyperparameters of LinearSVC() were a C value of 0.5 and a max_iter value of 2000, with a class_weight set to 'balanced'. This model's sentiment predictions scored an f1 score of 0.74810 on Kaggle agaisnt the true sentiments of the test data set, as this score is closer to 1 than 0, it can be suggested that the chosen 'best' model is higher in its precision and recall and is thus fairly effective in predicting/classifying tweet sentiments. This model can therefore be suggested as an approach companies can take to determine those who are anti- or pro- climate change and use this information to establish the developement and marketing of their climate friendly products and services. \n",
    "\n",
    "While all tested model's displayed decent f1 scores, future considerations for sentiment classification of this nature can include assessing what classifier alogorithms are best suited to the data at hand, as well as, running a grid search on all tested models to find optimal hyperparameters that improve on classififcation metric scores. More care can also be taken in the cleaning up of tweet datasets which in turn may also improve metric scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
